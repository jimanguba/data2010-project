---
title: "DATA-2010_Project"
author: "Jillian Manguba, Thien Pham, Kelly Villamayor, Abhinav Jain"
date: "2024-02-12"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## DATA 2010 Project

```{r}
nv_tourist <- read.csv("non-verbal tourist data.csv")
```

Note: Original dataset switched TAudio1 and Proxemics
new_nv_tourist rectified this error

```{r}

library(tidyverse)
new_nv_tourist <- nv_tourist |>
  rename(
    handshake_indiff = GImg1,
    hug_indiff = GImg2,
    kiss_indiff = GImg3,
    consent_post = PImg1,
    interest_post = PImg2,
    neutral_post = PImg3,
    reflexive_post = PImg4,
    negative_post = PImg5,
    relax_score = Tense...relaxed,
    anarchic_score = Authoritative..anarchic,
    friendly_score = Hostile...friendly,
    authoritative = Proxemics,
    sarcastic = TAudio2,
    friendly = TAudio3,
    spitting = QAudio1,
    hum = QAudio2,
    sigh = QAudio3,
    proxemics = TAudio1,
    client_type = Type.of.Client
  ) 
```

```{r}
# checking for missing values...

# the dataset uses "?" to indicate a missing value
contains_missing <- function(row) {
  any(row == "?")
}

rows_w_missing_val <- apply(new_nv_tourist, 1, contains_missing)
print(new_nv_tourist[rows_w_missing_val,])

```

Based off the results, it seems the missing values fall under MAR (missing at random). We decided to simply delete the rows that contained any missing values, since it is just 4 rows out of the total 73. Thus, it meets the 5-10% range for deletion in MAR.

```{r}
new_nv_tourist <- new_nv_tourist[!rows_w_missing_val,]
```